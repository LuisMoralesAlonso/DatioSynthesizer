{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import functools \n",
    "import sklearn.metrics as metrics\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = np.array([1,2,3,3,2,1])\n",
    "preds = np.array([4,5,4,4,5,5])\n",
    "true_classes, true_idx =np.unique(trues, return_inverse=True)\n",
    "print(true_classes)\n",
    "print(true_idx)\n",
    "pred_classes, pred_idx =np.unique(preds, return_inverse=True)\n",
    "print(metrics.mutual_info_score(trues, preds))\n",
    "print(pred_classes)\n",
    "print(pred_idx)\n",
    "n_classes = true_classes.shape[0]\n",
    "n_preds = pred_classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4620981203732969\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def partition_mutual_info_pre_score(true: pd.Series, pred: pd.Series):\n",
    "    datos = {}\n",
    "    true_classes, true_idx = np.unique(true, return_inverse=True)\n",
    "    datos['true_classes'] = true_classes\n",
    "    datos['true_idx'] = true_idx\n",
    "    pred_classes, pred_idx = np.unique(pred, return_inverse=True)\n",
    "    datos['pred_classes'] = pred_classes\n",
    "    datos['pred_idx'] = pred_idx\n",
    "    n_classes = true_classes.shape[0]\n",
    "    n_preds = pred_classes.shape[0]\n",
    "    datos['n_classes'] = n_classes\n",
    "    datos['n_preds'] = n_preds\n",
    "    contingency = sp.coo_matrix((np.ones(true_idx.shape[0]),\n",
    "                                 (true_idx, pred_idx)),\n",
    "                                shape=(n_classes, n_preds),\n",
    "                                dtype=np.int)\n",
    "    nzx, nzy, nz_val = sp.find(contingency)\n",
    "    datos['nzx'], datos['nzy'], datos['nz_val'] = nzx, nzy, nz_val\n",
    "    contingency_sum = contingency.sum()\n",
    "    datos['contingency_sum'] = contingency_sum\n",
    "    pi = np.ravel(contingency.sum(axis=1))\n",
    "    datos['pi'] = pi\n",
    "    pj = np.ravel(contingency.sum(axis=0))\n",
    "    datos['pj'] = pj\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed(nout=2)\n",
    "def gen_pi_pj(chunks_mi_list: list, true_classes: list, pred_classes: list):\n",
    "    #pi_dask = [0 for i in range(true_classes_len)]\n",
    "    pi_dask = np.zeros(len(true_classes))\n",
    "    pj_dask = np.zeros(len(pred_classes))\n",
    "    for mi_chunk in chunks_mi_list:\n",
    "        for index, clase in enumerate(true_classes):\n",
    "            try:\n",
    "                index_true_clase = mi_chunk['true_classes'].tolist().index(clase)\n",
    "                pi_dask[index] = pi_dask[index] + mi_chunk['pi'][mi_chunk['true_classes'].tolist().index(clase)]\n",
    "            except (IndexError, ValueError):\n",
    "                None\n",
    "        for index, clase in enumerate(pred_classes):\n",
    "            try:\n",
    "                index_pred_clase = mi_chunk['pred_classes'].tolist().index(clase)\n",
    "                pj_dask[index] = pj_dask[index] + mi_chunk['pj'][mi_chunk['pred_classes'].tolist().index(clase)]\n",
    "            except (IndexError, ValueError):\n",
    "                None\n",
    "    return (pi_dask, pj_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed(nout=3)\n",
    "def gen_nzx_nzy_nzval_dask(chunks_mi_list: list, true_classes, pred_classes):\n",
    "    nzx_dask, nzy_dask, nz_val_dask = np.array([], dtype=np.int64),np.array([], dtype=np.int64),np.array([], dtype=np.int64)\n",
    "    cross_clusters_list = []\n",
    "    for mi_chunk in chunks_mi_list:\n",
    "        true_nzx_np = np.array(list(map(lambda x: mi_chunk['true_classes'][x], mi_chunk['nzx'])))\n",
    "        true_nzy_np = np.array(list(map(lambda x: mi_chunk['pred_classes'][x], mi_chunk['nzy'])))\n",
    "        true_nz_val = mi_chunk['nz_val']\n",
    "        cross_clusters_list.append(Counter(dict(list(zip(zip(true_nzx_np,true_nzy_np),true_nz_val)))))\n",
    "    cross_clusters = dict(functools.reduce(lambda a,b : a+b,cross_clusters_list))\n",
    "    for key in cross_clusters.keys():\n",
    "        nzx_dask = np.append(nzx_dask, true_classes.tolist().index(key[0]))\n",
    "        nzy_dask = np.append(nzy_dask, pred_classes.tolist().index(key[1]))\n",
    "        nz_val_dask = np.append(nz_val_dask, cross_clusters[key])\n",
    "    return (nzx_dask, nzy_dask, nz_val_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def mutual_info_score(chunked_mi_list: list, trues: df.Series, preds: df.Series):\n",
    "    pi, pj = gen_pi_pj(chunked_mi_list, trues, preds)\n",
    "    nzx,nzy,nz_val = gen_nzx_nzy_nzval_dask(chunked_mi_list)\n",
    "    contingency_sum = get_contingency_sum(chunked_mi_list)\n",
    "    log_contingency_nm = np.log(nz_val)\n",
    "    print(log_contingency_nm)\n",
    "    contingency_nm = nz_val / contingency_sum\n",
    "    print(contingency_nm)\n",
    "    # Don't need to calculate the full outer product, just for non-zeroes\n",
    "    outer = pi.take(nzx).astype(np.int64) * pj.take(nzy).astype(np.int64)\n",
    "    print(pi.take(nzx).astype(np.int64))\n",
    "    print(outer)\n",
    "    print(pj.take(nzy).astype(np.int64))\n",
    "    log_outer = get_log_outer(outer,pi,pj)\n",
    "    mi = (contingency_nm * (log_contingency_nm - log(contingency_sum)) +\n",
    "          contingency_nm * log_outer)\n",
    "    return mi.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def get_log_outer(outer_delayed, pi_delayed, pj_delayed):\n",
    "    print(outer_delayed)\n",
    "    print(pi_delayed)\n",
    "    print(pj_delayed)\n",
    "    return -np.log(outer_delayed) + np.log(sum(pi_delayed)) + np.log(sum(pj_delayed))\n",
    "\n",
    "@dask.delayed\n",
    "def get_mi(contingency_nm_d, log_contingency_nm_d, contingency_sum_d, log_outer_d):\n",
    "    return (contingency_nm_d * (log_contingency_nm_d - log(contingency_sum_d)) +\n",
    "          contingency_nm_d * log_outer_d)\n",
    "\n",
    "@dask.delayed\n",
    "def get_contingency_sum(chunks_mi_list: list):\n",
    "    suma = 0\n",
    "    for mi_chunk in chunks_mi_list:\n",
    "        suma = suma + mi_chunk['contingency_sum']\n",
    "    return suma\n",
    "\n",
    "@dask.delayed\n",
    "def get_log_contingency_nm(nz_val_delayed):\n",
    "    return np.log(nz_val_delayed)\n",
    "\n",
    "@dask.delayed\n",
    "def get_contingency_nm(contingency_sum_delayed, nz_val_delayed):\n",
    "    contingency_nm = nz_val_delayed / contingency_sum_delayed\n",
    "    return contingency_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(true: df.DataFrame, pred: df.DataFrame):\n",
    "    #Mutual information of distributions in format of pd.Series or pd.DataFrame.\n",
    "    str_trues = true.astype(str).apply(lambda x: ' '.join(x.tolist()), axis=1, meta=('phrase', 'object'))\n",
    "    str_preds = pred.astype(str).apply(lambda x: ' '.join(x.tolist()), axis=1, meta=('phrase', 'object'))\n",
    "    true_classes = str_trues.unique()\n",
    "    pred_classes = str_preds.unique()\n",
    "    chunked_mi_list = list(map(lambda x: partition_mutual_info_pre_score(x[0],x[1]),list(zip(str_trues.to_delayed(), \n",
    "                                                                       str_preds.to_delayed()))))\n",
    "    pi, pj = gen_pi_pj(chunked_mi_list, true_classes, preds)\n",
    "    nzx,nzy,nz_val = gen_nzx_nzy_nzval_dask(chunked_mi_list, true_classes, pred_classes)\n",
    "    contingency_sum = get_contingency_sum(chunked_mi_list)\n",
    "    log_contingency_nm = get_log_contingency_nm(nz_val)\n",
    "    contingency_nm = get_contingency_nm(chunked_mi_list, nz_val)\n",
    "    \n",
    "    # Don't need to calculate the full outer product, just for non-zeroes\n",
    "    outer = pi.take(nzx).astype(np.int64) * pj.take(nzy).astype(np.int64)\n",
    "    log_outer = get_log_outer(outer, pi, pj)\n",
    "    mi = get_mi(contingency_nm, log_contingency_nm, contingency_sum, log_outer)\n",
    "    return mi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = df.from_pandas(pd.DataFrame([1,2,3,3,2,1]), npartitions=2)\n",
    "preds = df.from_pandas(pd.DataFrame([4,5,4,4,5,5]), npartitions=2)\n",
    "mi = mutual_information(trues, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cd3a9abdfde2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     postcomputes = [a.__dask_postcompute__() if is_dask_collection(a)\n\u001b[1;32m    391\u001b[0m                     else (None, a) for a in args]\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mresults_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     return tuple(a if f is None else f(next(results_iter), *a)\n",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[1;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                         \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                         \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/compatibility.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/idp/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0margs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5ce182d00f26>\u001b[0m in \u001b[0;36mget_contingency_nm\u001b[0;34m(contingency_sum_delayed, nz_val_delayed)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_contingency_nm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingency_sum_delayed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_val_delayed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcontingency_nm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnz_val_delayed\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcontingency_sum_delayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontingency_nm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (2,) "
     ]
    }
   ],
   "source": [
    "dask.compute(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_bayes(dataset: df.DataFrame, k=0: int, epsilon=0: float):\n",
    "    \"\"\"Construct a Bayesian Network (BN) using greedy algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset : DataFrame\n",
    "            Input dataset, which only contains categorical attributes.\n",
    "        k : int\n",
    "            Maximum degree of the constructed BN. If k=0, k is automatically calculated.\n",
    "        epsilon : float\n",
    "            Parameter of differential privacy.\n",
    "    \"\"\"\n",
    "\n",
    "    num_tuples, num_attributes = dataset.shape\n",
    "    if not k:\n",
    "        k = calculate_k(num_attributes, num_tuples)\n",
    "\n",
    "    attributes = set(dataset.keys())\n",
    "    N = []\n",
    "    V = set()\n",
    "    V.add(random.choice(attributes))\n",
    "\n",
    "    print('================== Constructing Bayesian Network ==================')\n",
    "    for i in range(1, len(attributes)):\n",
    "        print('Looking for next attribute-parents pair.')\n",
    "        rest_attributes = attributes - V\n",
    "        parents_pair_list = []\n",
    "        mutual_info_list = []\n",
    "        for child in rest_attributes:\n",
    "            print('    Considering attribute {}'.format(child))\n",
    "            for parents in combinations(V, min(k, len(V))):\n",
    "                parents = list(parents)\n",
    "                parents_pair_list.append((child, parents))\n",
    "                # TODO consider to change the computation of MI by combined integers instead of strings.\n",
    "                mi = mutual_information(dataset[child], dataset[parents])\n",
    "                mutual_info_list.append(mi)\n",
    "\n",
    "        if epsilon:\n",
    "            sampling_distribution = exponential_mechanism(dataset, mutual_info_list, epsilon)\n",
    "            idx = np.random.choice(list(range(len(mutual_info_list))), p=sampling_distribution)\n",
    "        else:\n",
    "            idx = mutual_info_list.index(max(mutual_info_list))\n",
    "\n",
    "        N.append(parents_pair_list[idx])\n",
    "        V.add(parents_pair_list[idx][0])\n",
    "\n",
    "    print('========================= BN constructed =========================')\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

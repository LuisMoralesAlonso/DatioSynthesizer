{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import functools \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[0 1 2 2 1 0]\n",
      "[4 5]\n",
      "[0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "true_classes, true_idx =np.unique([1,2,3,3,2,1], return_inverse=True)\n",
    "print(true_classes)\n",
    "print(true_idx)\n",
    "pred_classes, pred_idx =np.unique([4,5,4,4,5,5], return_inverse=True)\n",
    "print(pred_classes)\n",
    "print(pred_idx)\n",
    "n_classes = true_classes.shape[0]\n",
    "n_preds = pred_classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def partition_mutual_info_score(true: pd.Series, pred: pd.Series):\n",
    "    datos = {}\n",
    "    true_classes, true_idx = np.unique(true, return_inverse=True)\n",
    "    datos['true_classes'] = true_classes\n",
    "    datos['true_idx'] = true_idx\n",
    "    pred_classes, pred_idx = np.unique(pred, return_inverse=True)\n",
    "    datos['pred_classes'] = pred_classes\n",
    "    datos['pred_idx'] = pred_idx\n",
    "    n_classes = true_classes.shape[0]\n",
    "    n_preds = pred_classes.shape[0]\n",
    "    datos['n_classes'] = n_classes\n",
    "    datos['n_preds'] = n_preds\n",
    "    contingency = sp.coo_matrix((np.ones(true_idx.shape[0]),\n",
    "                                 (true_idx, pred_idx)),\n",
    "                                shape=(n_classes, n_preds),\n",
    "                                dtype=np.int)\n",
    "    nzx, nzy, nz_val = sp.find(contingency)\n",
    "    datos['nzx'], datos['nzy'], datos['nz_val'] = nzx, nzy, nz_val\n",
    "    contingency_sum = contingency.sum()\n",
    "    datos['contingency_sum'] = contingency_sum\n",
    "    pi = np.ravel(contingency.sum(axis=1))\n",
    "    datos['pi'] = pi\n",
    "    pj = np.ravel(contingency.sum(axis=0))\n",
    "    datos['pj'] = pj\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def gen_pi_dask(chunks_mi_delayed_list: list, true_classes_len: int):\n",
    "    #pi_dask = [0 for i in range(true_classes_len)]\n",
    "    pi_dask = np.zeros(true_classes_len)\n",
    "    for index, clase in enumerate(true_classes):\n",
    "        for mi_delayed in chunks_mi_delayed_list:\n",
    "            try:\n",
    "                index_clase = mi_delayed['true_classes'].tolist().index(clase)\n",
    "            except (IndexError, ValueError):\n",
    "                index_clase = None\n",
    "            if index_clase is not None:\n",
    "                pi_dask[index] = pi_dask[index] + mi_delayed['pi'][mi_delayed['true_classes'].tolist().index(clase)]\n",
    "    return pi_dask\n",
    "\n",
    "@dask.delayed\n",
    "def gen_pj_dask(chunks_mi_delayed_list: list, pred_classes_len: int):\n",
    "    #pj_dask = [0 for i in range(pred_classes_len)]\n",
    "    pj_dask = np.zeros(pred_classes_len)\n",
    "    for index, clase in enumerate(pred_classes):\n",
    "        for mi_delayed in chunks_mi_delayed_list:\n",
    "            try:\n",
    "                index_clase = mi_delayed['pred_classes'].tolist().index(clase)\n",
    "            except (IndexError, ValueError):\n",
    "                index_clase = None\n",
    "            if index_clase is not None:\n",
    "                pj_dask[index] = pj_dask[index] + mi_delayed['pj'][mi_delayed['pred_classes'].tolist().index(clase)]\n",
    "    return pj_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def gen_nzx_nzy_nzval_dask(chunks_mi_delayed_list: list):\n",
    "    nzx_dask, nzy_dask, nz_val_dask = np.array([], dtype=np.int64),np.array([], dtype=np.int64),np.array([], dtype=np.int64)\n",
    "    cross_clusters_list = []\n",
    "    for mi_delayed in chunks_mi_delayed_list:\n",
    "        true_nzx_np = np.array(list(map(lambda x: mi_delayed['true_classes'][x], mi_delayed['nzx'])))\n",
    "        true_nzy_np = np.array(list(map(lambda x: mi_delayed['pred_classes'][x], mi_delayed['nzy'])))\n",
    "        true_nz_val = mi_delayed['nz_val']\n",
    "        cross_clusters_list.append(Counter(dict(list(zip(zip(true_nzx_np,true_nzy_np),true_nz_val)))))\n",
    "    cross_clusters = dict(functools.reduce(lambda a,b : a+b,cross_clusters_list))\n",
    "    for key in cross_clusters.keys():\n",
    "        nzx_dask = np.append(nzx_dask, true_classes.tolist().index(key[0]))\n",
    "        nzy_dask = np.append(nzy_dask, pred_classes.tolist().index(key[1]))\n",
    "        nz_val_dask = np.append(nz_val_dask, cross_clusters[key])\n",
    "    return (nzx_dask, nzy_dask, nz_val_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def contingency_sum_dask(chunks_mi_delayed_list: list):\n",
    "    suma = 0\n",
    "    for mi_delayed in chunks_mi_delayed_list:\n",
    "        suma = suma + mi_delayed['contingency_sum']\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def get_mi(chunks_mi: list, true_len: int, pred_len: int):\n",
    "    pi = gen_pi_dask(delayes, 3)\n",
    "    pj = gen_pj_dask(delayes, 2)\n",
    "    nzx_nzy_nz_val = gen_nzx_nzy_nzval_dask(delayes)\n",
    "    contingency_sum = contingency_sum(delayes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_1 = partition_mutual_info_score([1,2,3], [4,5,4])\n",
    "datos_2 = partition_mutual_info_score([3,2,1], [4,5,5])\n",
    "delayes = [datos_1,datos_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_delayed = gen_pi_dask(delayes, 3)\n",
    "pj_delayed = gen_pj_dask(delayes, 2)\n",
    "nzx_nzy_nz_val_delayed = gen_nzx_nzy_nzval_dask(delayes)\n",
    "contingency_sum_delayed = contingency_sum_dask(delayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = dask.compute(pi_delayed)[0]\n",
    "pj = dask.compute(pj_delayed)[0]\n",
    "nzx_nzy_nz_val = dask.compute(nzx_nzy_nz_val_delayed)[0]\n",
    "contingency_sum = dask.compute(contingency_sum_delayed)[0]\n",
    "nzx, nzy, nz_val = nzx_nzy_nz_val[0], nzx_nzy_nz_val[1], nzx_nzy_nz_val[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.69314718 0.69314718 0.        ]\n",
      "[0.16666667 0.33333333 0.33333333 0.16666667]\n",
      "[2 2 2 2]\n",
      "[6 6 6 6]\n",
      "[3 3 3 3]\n",
      "0.4620981203732969\n"
     ]
    }
   ],
   "source": [
    "log_contingency_nm = np.log(nz_val)\n",
    "print(log_contingency_nm)\n",
    "contingency_nm = nz_val / contingency_sum\n",
    "print(contingency_nm)\n",
    "# Don't need to calculate the full outer product, just for non-zeroes\n",
    "outer = pi.take(nzx).astype(np.int64) * pj.take(nzy).astype(np.int64)\n",
    "print(pi.take(nzx).astype(np.int64))\n",
    "print(outer)\n",
    "print(pj.take(nzy).astype(np.int64))\n",
    "log_outer = -np.log(outer) + log(sum(pi)) + log(sum(pj))\n",
    "mi = (contingency_nm * (log_contingency_nm - log(contingency_sum)) +\n",
    "          contingency_nm * log_outer)\n",
    "print(mi.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
